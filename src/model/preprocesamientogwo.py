# -*- coding: utf-8 -*-
"""PreprocesamientoGWO.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1PTyWb7pRdpeh9gj5nwPJ6mtoXq203FuZ
"""

import pandas as pd
import numpy as np

# Cargar el archivo server_usage
server_usage18 = pd.read_csv('/content/dataset_serv.csv')

# Cargar el archivo batch_task
batch_task18 = pd.read_csv('/content/dataset_task.csv')

# Renombrar columnas en server_usage.csv
server_usage18.columns = ['machine_id', 'time_stamp ', 'cpu_util_percent', 'mem_util_percent', 'mem_gps',
                        'mkpi', 'net_in', 'net_out', ' disk_io_percent']

# Renombrar columnas en batch_task.csv
batch_task18.columns = ['task_name', 'instance_num', 'job_name', 'task_type', 'status', 'start_time',
                      'end_time', 'plan_cpu', 'plan_mem']

# Verificar los cambios
print(server_usage18.head())
print(batch_task18.head())

# Calcular el porcentaje de valores faltantes para cada columna en server_usage18
missing_percentage_server = (server_usage18.isnull().sum() / len(server_usage18)) * 100

# Imprimir el porcentaje de valores faltantes para server_usage18
print("Porcentaje de valores faltantes en server_usage18:")
print(missing_percentage_server)

# Calcular el porcentaje de valores faltantes para cada columna en batch_task18
missing_percentage_batch = (batch_task18.isnull().sum() / len(batch_task18)) * 100

# Imprimir el porcentaje de valores faltantes para batch_task18
print("\nPorcentaje de valores faltantes en batch_task18:")
print(missing_percentage_batch)

from sklearn.preprocessing import MinMaxScaler

# Eliminar columnas irrelevantes en server_usage18 con alto Ã­ndice de valores faltantes
if 'mem_gps' in server_usage18.columns and 'mkpi' in server_usage18.columns:
    server_usage18 = server_usage18.drop(columns=['mem_gps', 'mkpi'])

# Llenar valores faltantes en instance_num con la mediana
batch_task18['instance_num'] = batch_task18['instance_num'].fillna(batch_task18['instance_num'].median())

# Llenar valores faltantes en plan_cpu y plan_mem usando relaciones con otras columnas
if 'plan_cpu' in batch_task18.columns and 'plan_mem' in batch_task18.columns:
    batch_task18['plan_cpu'] = batch_task18['plan_cpu'].fillna(
        batch_task18['instance_num'] * (batch_task18['plan_cpu'].mean() / batch_task18['instance_num'].mean())
    )
    batch_task18['plan_mem'] = batch_task18['plan_mem'].fillna(
        batch_task18['instance_num'] * (batch_task18['plan_mem'].mean() / batch_task18['instance_num'].mean())
    )

# Crear la columna 'duration' como la diferencia entre 'end_time' y 'start_time'
if 'end_time' in batch_task18.columns and 'start_time' in batch_task18.columns:
    batch_task18['duration'] = batch_task18['end_time'] - batch_task18['start_time']

# Escalar columnas seleccionadas en batch_task18
scaler = MinMaxScaler()
columns_to_scale_batch = ['plan_cpu', 'plan_mem', 'instance_num', 'duration']
for col in columns_to_scale_batch:
    if col in batch_task18.columns:
        batch_task18[col] = scaler.fit_transform(batch_task18[[col]])

# Escalar columnas seleccionadas en server_usage18
columns_to_scale_server = ['cpu_util_percent', 'mem_util_percent', 'net_in', 'net_out']
for col in columns_to_scale_server:
    if col in server_usage18.columns:
        server_usage18[col] = scaler.fit_transform(server_usage18[[col]])

# Guardar los datasets limpios y escalados
server_usage18.to_csv('server_usage18_cleaned.csv', index=False)
batch_task18.to_csv('batch_task18_cleaned.csv', index=False)

# Lee los archivos 'server_usage18_cleaned.csv' y 'batch_task18_cleaned.csv'
server_usage_cleaned = pd.read_csv('server_usage18_cleaned.csv')
batch_task_cleaned = pd.read_csv('batch_task18_cleaned.csv')

# Muestra las primeras filas de cada archivo
print("server_usage18_cleaned:")
print(server_usage_cleaned)

print("\nbatch_task18_cleaned:")
print(batch_task_cleaned)